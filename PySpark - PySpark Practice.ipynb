{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6b3cbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\silri\\\\spark-3.3.0-bin-hadoop3\\\\spark-3.3.0-bin-hadoop3'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74b5d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "673ff558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\silri\\\\spark-3.3.0-bin-hadoop3\\\\spark-3.3.0-bin-hadoop3'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dac215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc3059b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('NewToPySpark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10bc298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= SparkContext.getOrCreate(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3cc6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Alll']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"C:\\\\Users\\\\silri\\\\Downloads\\\\Hello.txt\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc247c",
   "metadata": {},
   "source": [
    "### Quiz 1\n",
    "\n",
    "For the quiz you’ll be using this input file\n",
    "\n",
    "***`Hi how are you?\n",
    "Hope you are doing\n",
    "great`***\n",
    "\n",
    "Read this file in the RDD\n",
    "Write a mapper that will provide the length of each word in the following format\n",
    "\n",
    "[ [2, 3, 3, 4], [4, 3, 3, 5], [5] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0929e",
   "metadata": {},
   "source": [
    "#### 1st method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "992ec42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silri\\OneDrive\\Documents\\PySpark\\DataSets\\RDDs\\quiz1.csv\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\silri\\\\OneDrive\\\\Documents\\\\PySpark\\\\DataSets\\\\RDDs\\\\'\n",
    "file = 'quiz1.csv'\n",
    "print(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c4c42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc966c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi How Are you?', 'Hope you are doing', 'great']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c4f251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Length of each word giving format of a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c30abb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = rdd.map(lambda x : x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7aa722c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_list = []\n",
    "for i in rdd1.collect():\n",
    "    _list1 = []\n",
    "    for j in i:\n",
    "        _list1.append(len(j))        \n",
    "    _list.append(_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da6adeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 3, 4], [4, 3, 3, 5], [5]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce3c67",
   "metadata": {},
   "source": [
    "**But in this way we are not getting the data in rdd format**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519802e",
   "metadata": {},
   "source": [
    "#### Better Way : -\n",
    "\n",
    "1. Create a function for x\n",
    "2. Apply that using map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b628589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_length(x):\n",
    "    _list = []\n",
    "    word_list = x.split(' ')\n",
    "    for i in word_list:\n",
    "        _list.append(len(i))\n",
    "    return _list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f548366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi How Are you?', 'Hope you are doing', 'great']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0537ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 3, 4], [4, 3, 3, 5], [5]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(find_length).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74c3c762",
   "metadata": {},
   "source": [
    "### Quiz 2\n",
    "\n",
    "For the quiz you’ll be using this input file\n",
    "\n",
    "***`this mango company animal\n",
    "cat dog ant mic laptop\n",
    "chair switch mobile am charger cover\n",
    "amanda any alarm ant`***\n",
    "\n",
    "Read this file in the RDD\n",
    "Write a filter that will remove all the words that are either starting from a or c from the rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97e5e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_q2 = sc.textFile('C:\\\\Users\\\\silri\\\\OneDrive\\\\Documents\\\\PySpark\\\\DataSets\\\\RDDs\\\\quiz2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01114fb7",
   "metadata": {},
   "source": [
    "**Method 1**\n",
    "\n",
    "1. We will create a function.\n",
    "2. Apply that using ***`map()`*** or ***`flatMap()`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df63606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ac(word_list):\n",
    "    word_wo_ac=[]\n",
    "    for word in word_list:\n",
    "        if not (word.startswith('a') or word.startswith('c')):\n",
    "            word_wo_ac.append(word)            \n",
    "    return word_wo_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96821b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'mango']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_ac(['this','mango','company','animal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae0171a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'mango', 'dog', 'mic', 'laptop', 'switch', 'mobile']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_q2.map(lambda x : x.split(' ')).flatMap(remove_ac).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd313eec",
   "metadata": {},
   "source": [
    "**Method 2**\n",
    "\n",
    "1. Lets try if we can use ***`filter()`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eae4f637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this mango company animal',\n",
       " 'cat dog ant mic laptop',\n",
       " 'chair switch mobile am charger cover',\n",
       " 'amanda any alarm ant']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_q2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8f5d775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'mango', 'dog', 'mic', 'laptop', 'switch', 'mobile']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_q2.flatMap(lambda x : x.split(' ')). \\\n",
    "filter(lambda x : False if (x.startswith('a') or x.startswith('c')) else True). \\\n",
    "collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f33085e",
   "metadata": {},
   "source": [
    "### Quiz 3 \n",
    "\n",
    "For the quiz you’ll be using this input file\n",
    "\n",
    "***`this mango company \n",
    "cat mango ant animal laptop\n",
    "chair switch mango am charger cover\n",
    "animalany mango ant laptop laptop\n",
    "this`***\n",
    "\n",
    "Read this file in the RDD\n",
    "Write a transformation flow that will return the word count of each word present in the file as (key, value) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a21222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this mango company ',\n",
       " 'cat mango ant animal laptop',\n",
       " 'chair switch mango am charger cover',\n",
       " 'animalany mango ant laptop laptop',\n",
       " 'this']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_q3 = sc.textFile('C:\\\\Users\\\\silri\\\\OneDrive\\\\Documents\\\\PySpark\\\\DataSets\\\\RDDs\\\\quiz3.csv')\n",
    "rdd_q3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff7cf228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_temp3 = rdd_q3.flatMap(lambda x : x.split(' ')).filter(lambda x : True if x!='' else False).map(lambda x : (x,1))\n",
    "rdd_final = rdd_temp3.reduceByKey(lambda x,y : x+y)\n",
    "Final_list = list(rdd_final.collect())\n",
    "type(Final_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "198fee55",
   "metadata": {},
   "source": [
    "### Quiz 4\n",
    "\n",
    "For the quiz you’ll be using this input file\n",
    "\n",
    "***`\n",
    "JAN,NY,3.0\n",
    "JAN,PA,1.0\n",
    "JAN,NJ,2.0\n",
    "JAN,CT,4.0\n",
    "FEB,PA,1.0\n",
    "`***\n",
    "\n",
    "Read this file in the RDD\n",
    "Write a code to calculate the average score in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c77a491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JAN,NY,3.0', 'JAN,PA,1.0', 'JAN,NJ,2.0', 'JAN,CT,4.0', 'FEB,PA,1.0']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_q4 = sc.textFile('C:\\\\Users\\\\silri\\\\OneDrive\\\\Documents\\\\PySpark\\\\DataSets\\\\RDDs\\\\quiz4.csv')\n",
    "rdd_q4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bbd7bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rdd_q4.map(lambda x : x.split(',')).map(lambda x : (x[0],(float(x[2]),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eca4aaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JAN', (3.0, 1)),\n",
       " ('JAN', (1.0, 1)),\n",
       " ('JAN', (2.0, 1)),\n",
       " ('JAN', (4.0, 1)),\n",
       " ('FEB', (1.0, 1))]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3a9bfd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1  = temp.reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "21b42e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JAN', (10.0, 4)), ('FEB', (1.0, 1))]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3fb766fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JAN', 2.5), ('FEB', 1.0)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.map(lambda x : (x[0],x[1][0]/x[1][1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270aa3cd",
   "metadata": {},
   "source": [
    "### Quiz5\n",
    "\n",
    "***`\n",
    "JAN,NY,3.0\n",
    "JAN,PA,1.0\n",
    "JAN,NJ,2.0\n",
    "JAN,CT,4.0\n",
    "FEB,PA,1.0\n",
    "`***\n",
    "\n",
    "Read this file in the RDD\n",
    "Write a code to calculate the Minimum and Maximum rating given by each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "01629e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JAN,NY,3.0', 'JAN,PA,1.0', 'JAN,NJ,2.0', 'JAN,CT,4.0', 'FEB,PA,1.0']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_q5 = sc.textFile('C:\\\\Users\\\\silri\\\\OneDrive\\\\Documents\\\\PySpark\\\\DataSets\\\\RDDs\\\\quiz5.csv')\n",
    "rdd_q5.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0195f139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', 3.0), ('PA', 1.0), ('NJ', 2.0), ('CT', 4.0), ('PA', 1.0)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = rdd_q5.map(lambda x : x.split(',')).map(lambda x : (x[1],float(x[2])))\n",
    "temp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "de837c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', <pyspark.resultiterable.ResultIterable at 0x23e5d155520>),\n",
       " ('CT', <pyspark.resultiterable.ResultIterable at 0x23e5d22e610>),\n",
       " ('PA', <pyspark.resultiterable.ResultIterable at 0x23e5d22e5b0>),\n",
       " ('NJ', <pyspark.resultiterable.ResultIterable at 0x23e5d22e6d0>)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028792a",
   "metadata": {},
   "source": [
    "The groupBy() operation is returning key-value pair, where the value is iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7c597db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[264] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fc83d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', [3.0]), ('CT', [4.0]), ('PA', [1.0, 1.0]), ('NJ', [2.0])]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupByKey().mapValues(list).map(lambda x : x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af7205",
   "metadata": {},
   "source": [
    "[('NY', [3.0]), ('CT', [4.0]), **('PA', `[1.0, 1.0]`)**, ('NJ', [2.0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "df711471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NY', 3.0, 3.0], ['CT', 4.0, 4.0], ['PA', 1.0, 1.0], ['NJ', 2.0, 2.0]]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupByKey().mapValues(list).map(lambda x : [x[0],min(x[1]),max(x[1])]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf20d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
